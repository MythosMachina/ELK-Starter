# ELK Starter üöÄ

> Moderner Entwicklungs-Stack f√ºr Elasticsearch, Kibana & Fleet Server ‚Äì automatisiert per Docker Compose.

![Docker Compose](https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker&logoColor=white)
![Elastic Stack](https://img.shields.io/badge/Elastic%20Stack-8.x-005571?logo=elastic&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)

## Inhaltsverzeichnis

1. [√úberblick](#√ºberblick)
2. [Highlights](#highlights)
3. [Projektstruktur](#projektstruktur)
4. [Voraussetzungen](#voraussetzungen)
5. [Setup ‚Äì Schritt f√ºr Schritt](#setup--schritt-f√ºr-schritt)
6. [Nach dem Start](#nach-dem-start)
7. [Elastic Agent Onboarding](#elastic-agent-onboarding)
8. [Betrieb & Wartung](#betrieb--wartung)
9. [Troubleshooting & Ressourcen](#troubleshooting--ressourcen)

---

## √úberblick

Dieses Repository liefert ein vorkonfiguriertes Docker-Compose-Stack f√ºr einen einzelnen Elasticsearch-Knoten, Kibana sowie einen Fleet Server. Es richtet sich an Lab- und Entwicklungsumgebungen und greift auf die Vorgaben in [`agents.md`](agents.md) zur√ºck, um ein reproduzierbares Setup zu bieten ‚Äì inklusive Provisionierungsskripten, TLS per Caddy-Proxy und persistenter Ablage der Daten auf dem Host.

## Highlights

| ‚úÖ Feature | Beschreibung |
| --- | --- |
| **One-Command-Provisioning** | `scripts/provision.sh` k√ºmmert sich um Docker, Kernel-Tuning (`vm.max_map_count`) und Verzeichnisstruktur. |
| **Automatisierte Zertifikate** | `scripts/generate-certs.sh` erzeugt eine lokale CA, √ºbernimmt Domains aus `.env` sowie Container-Hostnamen in die SAN-Liste und warnt vor √úberschreibungen bestehender Zertifikate. |
| **Sicherer Fleet-Start** | `scripts/start.sh` startet Elasticsearch & Caddy, erstellt ein frisches Kibana-Service-Token und bringt Fleet/Kibana danach online. |
| **Interactive Setup** | `scripts/setup.sh` vereint alle Schritte in einem Men√º mit Rollback-, Secrets- und Directory-Optionen. |
| **Fleet-Agent-Installer** | Skripte f√ºr Linux & Windows enrollen den Elastic Agent direkt gegen den mitgelieferten Fleet Server. |

## Projektstruktur

| Pfad | Inhalt |
| --- | --- |
| `docker-compose.yml` | Definition des Stacks (Elasticsearch, Kibana, Fleet Server, Caddy). |
| `.env` | Zentrale Variablen wie `STACK_VERSION`, Passw√∂rter und √∂ffentliche URLs. |
| `scripts/` | Provisionierung, Zertifikatsgenerierung, Start/Setup sowie Agent-Installer. |
| `configs/` | Vorkonfigurierte `elasticsearch.yml`, `kibana.yml` und Fleet-Konfigurationen. |
| `certs/` | Platz f√ºr selbstsignierte CA, Zertifikate und Schl√ºssel (generiert durch Skript). |
| `systemd/` | Optionale Unit, um den Stack als Service zu betreiben. |
| `/mnt/elastic_logs/` (Host) | Persistente Daten & Logs f√ºr Elasticsearch, Kibana und Fleet Server. |

## Voraussetzungen

- Linux-Host mit Docker Engine ‚â• 24 und Docker Compose Plugin.
- `sudo`-Rechte f√ºr Provisionierung und Kernel-Anpassungen.
- (Optional) `jq` f√ºr die Smoke-Tests.
- DNS- oder Hosts-Eintr√§ge, damit `es.local`, `kibana.local` und `fleet.local` auf den Host zeigen.

> ‚ÑπÔ∏è Passe die Werte in `.env` vor dem Start an (Passwort, URLs, Heap-Gr√∂√üe usw.).

## Setup ‚Äì Schritt f√ºr Schritt

```mermaid
graph LR
  A[Repo klonen] --> B[.env anpassen]
  B --> C[Provisionieren]
  C --> D[Zertifikate erzeugen]
  D --> E[Stack starten]
  E --> F[Smoke-Test]
```

1. **Repository vorbereiten**
   ```bash
   git clone https://github.com/<dein-user>/ELK-Starter.git
   cd ELK-Starter
   cp .env .env.local && edit .env.local  # optionaler Backup/Anpassung
   ```
   > Tipp: `scripts/setup.sh` f√ºhrt dich interaktiv durch Domain- und Pfad-Anpassungen.

2. **Provisionierung ausf√ºhren** ‚Äì richtet Docker, Kernel-Werte und Ordnerstruktur ein.
   ```bash
   sudo bash scripts/provision.sh
   ```

3. **TLS-Zertifikate generieren** ‚Äì erstellt eine lokale CA und Service-Zertifikate im Ordner `certs/`.
   ```bash
   bash scripts/generate-certs.sh
   ```
   - Bezieht die √∂ffentlichen URLs aus `.env` sowie die Container-Namen (`es01`, `kibana`, `fleet-server`, `caddy`) in jedes Zertifikat mit ein.
   - Erkennt vorhandene Zertifikate und fragt nach, bevor Schl√ºssel oder CA ersetzt werden.

4. **Stack starten** ‚Äì Elasticsearch, Kibana, Fleet Server und Caddy werden hochgefahren.
   ```bash
   bash scripts/start.sh
   ```

   - Das Skript r√§umt `KIBANA_SERVICE_TOKEN` in `.env` auf und schreibt ein frisches Token zur√ºck.
   - Fleet Server und Kibana starten erst, nachdem Elasticsearch gesund ist.

5. **Optional: Interaktiver Modus**
   ```bash
   bash scripts/setup.sh
   ```
   Men√º-Optionen decken Umgebungsvariablen, Persistenzpfade, Abh√§ngigkeiten, Rollback sowie eine √úbersicht √ºber URLs und Secrets ab.

## Nach dem Start

- **Zug√§nge**
  - Elasticsearch: `https://es.local`
  - Kibana: `https://kibana.local`
  - Fleet Server: `https://fleet.local`

- **Smoke-Test**
  ```bash
  curl -s --cacert certs/ca.crt -u elastic:$ELASTIC_PASSWORD https://es.local | jq .
  ```

- **Kibana Login** mit Benutzer `elastic` und dem Passwort aus `.env`.

- **Service Token pr√ºfen**: `grep KIBANA_SERVICE_TOKEN .env`.

## Elastic Agent Onboarding

Verwende die mitgelieferten Skripte, um Agents automatisiert im Fleet Server zu registrieren. Setze dazu `ENROLLMENT_TOKEN` auf das Token aus Kibana ‚Üí Fleet ‚Üí Enrollment-Tokens.

### Linux

```bash
ENROLLMENT_TOKEN=<token> bash scripts/install-agent-linux.sh
```

### Windows (PowerShell)

```powershell
./scripts/install-agent-windows.ps1 -EnrollmentToken <token>
```

Beide Skripte nutzen standardm√§√üig die `STACK_VERSION` aus `.env` und laden den passenden Agent direkt von Elastic.

## Betrieb & Wartung

| Aufgabe | Befehl(e) |
| --- | --- |
| **Status pr√ºfen** | `docker compose ps` |
| **Logs streamen** | `docker compose logs -f es01`, `docker compose logs -f kibana`, `docker compose logs -f fleet-server` |
| **Stack stoppen** | `docker compose down` |
| **Stack neu starten** | `bash scripts/start.sh` oder `docker compose up -d` |
| **Images aktualisieren** | `docker compose pull` gefolgt von `docker compose up -d --remove-orphans` |
| **Persistente Daten** | Liegen unter `/mnt/elastic_logs/<dienst>/` (Config, Daten, Logs). |
| **Systemd-Betrieb** | `sudo cp systemd/elk-stack.service /etc/systemd/system/` ‚Üí `sudo systemctl enable --now elk-stack` |

> üì¶ **Backup-Empfehlung:** Elasticsearch-Snapshots (API) plus Sicherung der Verzeichnisse unter `/mnt/elastic_logs/`.

## Troubleshooting & Ressourcen

- Details zur Topologie, Kernel-Parametern und Sicherheitsempfehlungen findest du in [`agents.md`](agents.md).
- Typische Stolperfallen:
  - `vm.max_map_count` zu niedrig ‚Üí Provisionierung erneut ausf√ºhren oder `sudo sysctl -w vm.max_map_count=262144` setzen.
  - Kibana nicht erreichbar ‚Üí `docker compose logs kibana` pr√ºfen und sicherstellen, dass Elasticsearch gr√ºn ist (`curl /_cluster/health`).
  - Fleet Agent kann sich nicht registrieren ‚Üí CA (`certs/ca.crt`) und `FLEET_PUBLIC_URL`/`FLEET_URL` in `.env` √ºberpr√ºfen.
- Offizielle Elastic-Dokumentation: [Elastic Agent Environments](https://www.elastic.co/docs/reference/fleet/agent-environment-variables) & [Elasticsearch Docker Guide](https://www.elastic.co/docs/deploy-manage/deploy/self-managed/install-elasticsearch-docker-prod).

Viel Erfolg beim Aufbau deiner Observability-Umgebung! üí°
